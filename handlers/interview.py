from aiogram import Dispatcher, types
from aiogram.types import CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from services.openai_service import client, questions, evaluate_answers
import os
import tempfile
from pydub import AudioSegment
import speech_recognition as sr

class InterviewStates(StatesGroup):
    WELCOME = State()
    ASK_QUESTION = State()
    WAIT_ANSWER = State()
    SHOW_REPORT = State()

async def interview_welcome(callback: CallbackQuery, state: FSMContext):
    await state.update_data(current_question=0, questions_and_answers=[])
    welcome_message = (
        "–í—ã –±—É–¥–µ—Ç–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ 15 –≤–æ–ø—Ä–æ—Å–æ–≤. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–ª—å—Å–∫–æ–º —è–∑—ã–∫–µ, —Ç–∞–∫ –∫–∞–∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –±—É–¥–µ—Ç –ø—Ä–æ–≤–æ–¥–∏—Ç—å—Å—è –Ω–∞ —ç—Ç–æ–º —è–∑—ã–∫–µ.\n\n"
        "–í–∞–∂–Ω–æ: –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∫–∞–∫ –ø–∏—Å—å–º–µ–Ω–Ω–æ, —Ç–∞–∫ –∏ –≥–æ–ª–æ—Å–æ–º. –ì–ª–∞–≤–Ω–æ–µ, –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ø–æ–ª—å—Å–∫–æ–º. –ï—Å–ª–∏ –≤—ã –æ—Ç–≤–µ—á–∞–µ—Ç–µ –≥–æ–ª–æ—Å–æ–º, –ø–æ—Å—Ç–∞—Ä–∞–π—Ç–µ—Å—å –≥–æ–≤–æ—Ä–∏—Ç—å —á–µ—Ç–∫–æ –∏ —Ä–∞–∑–±–æ—Ä—á–∏–≤–æ, —á—Ç–æ–±—ã –≤–∞—à –æ—Ç–≤–µ—Ç –º–æ–≥ –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ –æ—Ü–µ–Ω–µ–Ω."
    )
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–ù–∞—á–∞—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ", callback_data="start_interview")]
    ])
    await callback.message.answer(welcome_message, reply_markup=keyboard)
    await state.set_state(InterviewStates.WELCOME)

async def start_interview(callback: CallbackQuery, state: FSMContext):
    await ask_next_question(callback.message, state)

async def ask_next_question(message: types.Message, state: FSMContext):
    data = await state.get_data()
    current_question = data['current_question']
    if current_question < len(questions):
        question = questions[current_question]
        await state.set_state(InterviewStates.WAIT_ANSWER)
        await message.answer(question)
    else:
        await show_report(message, state)

async def handle_user_answer(message: types.Message, state: FSMContext):
    data = await state.get_data()
    current_question = data['current_question']
    questions_and_answers = data['questions_and_answers']
    question = questions[current_question]

    if message.voice:
        # Get voice message
        file_id = message.voice.file_id
        file = await message.bot.get_file(file_id)
        file_path = file.file_path

        # Download voice message
        with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as temp_file:
            await message.bot.download_file(file_path, temp_file.name)
            audio_path = temp_file.name

        try:
            # Convert OGG to WAV using pydub
            audio = AudioSegment.from_file(audio_path, format="ogg")
            wav_path = audio_path.replace(".ogg", ".wav")
            audio.export(wav_path, format="wav")

            # Use speech_recognition to transcribe the WAV file
            recognizer = sr.Recognizer()
            with sr.AudioFile(wav_path) as source:
                audio_data = recognizer.record(source)  # Read the entire audio file
                user_answer = recognizer.recognize_google(audio_data, language="pl-PL")

        except Exception as e:
            print(f"Error: {e}")
            await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç.")
            return
    else:
        user_answer = message.text

    # Update state
    questions_and_answers.append({"question": question, "answer": user_answer})
    await state.update_data(
        current_question=current_question + 1,
        questions_and_answers=questions_and_answers
    )

    await ask_next_question(message, state)

async def show_report(message: types.Message, state: FSMContext):
    data = await state.get_data()
    questions_and_answers = data['questions_and_answers']

    # Evaluate all answers
    evaluation = await evaluate_answers(questions_and_answers)
    
    # Extract scores and calculate average score
    scores = [int(line.split("–ë–∞–ª–ª—ã: ")[1].split("/")[0]) for line in evaluation.split("\n") if "–ë–∞–ª–ª—ã: " in line]
    total_score = sum(scores)
    average_score = total_score / len(scores) if scores else 0

    # Form full report
    report = f"""
<b>üìÑ –í–∞—à –æ—Ç—á–µ—Ç –æ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏:</b>
<b>üèÖ –û–±—â–∏–π –±–∞–ª–ª:</b> {total_score} –∏–∑ {len(scores) * 10}
<b>üìä –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª:</b> {average_score:.2f}

<b>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:</b> {'–í—ã —Ö–æ—Ä–æ—à–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é.' if average_score >= 7 else '–í–∞–º —Å—Ç–æ–∏—Ç –ª—É—á—à–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é.'}

<b>üîç –ü–æ–¥—Ä–æ–±–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–∞—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤:</b>
{evaluation}
    """

    # Split report into multiple messages if it exceeds Telegram's message length limit
    MAX_MESSAGE_LENGTH = 4096
    messages = [report[i:i + MAX_MESSAGE_LENGTH] for i in range(0, len(report), MAX_MESSAGE_LENGTH)]

    # Send each part of the report as a separate message
    for part in messages:
        await message.answer(part, parse_mode="HTML")

    # Button to return to main menu
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="main_menu")]
    ])
    await message.answer("–û—Ç—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –í–µ—Ä–Ω—É—Ç—å—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=keyboard)
    await state.clear()


async def return_to_main_menu(callback: CallbackQuery, state: FSMContext):
    keyboard = InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ä–æ–≤–Ω—è —è–∑—ã–∫–∞", callback_data="test")],
        [InlineKeyboardButton(text="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—é", callback_data="interview")]
    ])
    await callback.message.answer("–í—ã –≤–µ—Ä–Ω—É–ª–∏—Å—å –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é. –í—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω—ã–π —Ä–∞–∑–¥–µ–ª:", reply_markup=keyboard)
    await callback.answer()
    await state.clear()

def register_interview_handlers(dp: Dispatcher):
    dp.callback_query.register(interview_welcome, lambda c: c.data == "interview")
    dp.callback_query.register(start_interview, lambda c: c.data == "start_interview")
    dp.message.register(handle_user_answer, InterviewStates.WAIT_ANSWER)
    dp.callback_query.register(return_to_main_menu, lambda c: c.data == "main_menu")
